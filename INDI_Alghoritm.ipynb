{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodolforpr14/Rodolfo-s-Works/blob/main/INDI_Alghoritm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Remove TGHD, do the expected application and Mark the Top ads (ads responsible to bring 80% of total expected application)**"
      ],
      "metadata": {
        "id": "WXX0E3zJysp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_pyjqEuEl8Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f750f514-12cf-46fa-9ebe-3f08902e9319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Title from JD Sheet  \\\n",
            "0         Junior .NET Developer - EN   \n",
            "1          .NET Junior Engineer - EN   \n",
            "2         Junior .NET Developer - EN   \n",
            "3                .NET Tech Lead - EN   \n",
            "4                .NET Developer - EN   \n",
            "..                               ...   \n",
            "116   Quality Assurance Analyst - EN   \n",
            "117   Quality Assurance Analyst - EN   \n",
            "118        TypeScript Developer - EN   \n",
            "119  User Experience Specialist - EN   \n",
            "120  User Experience Specialist - EN   \n",
            "\n",
            "                                             Seniority  \\\n",
            "0                  Junior / Assistant / Junior Analyst   \n",
            "1                  Junior / Assistant / Junior Analyst   \n",
            "2                  Junior / Assistant / Junior Analyst   \n",
            "3    Lead / Leader / Manager / Tech Lead / Engineer...   \n",
            "4                                Semi Senior / Analyst   \n",
            "..                                                 ...   \n",
            "116                              Semi Senior / Analyst   \n",
            "117                              Semi Senior / Analyst   \n",
            "118                              Semi Senior / Analyst   \n",
            "119                              Semi Senior / Analyst   \n",
            "120                              Semi Senior / Analyst   \n",
            "\n",
            "                       Technology                      Location  \\\n",
            "0              .NET / C# / VB.NET                 Latin America   \n",
            "1              .NET / C# / VB.NET                 Latin America   \n",
            "2              .NET / C# / VB.NET                        Brazil   \n",
            "3              .NET / C# / VB.NET       Salvador, Bahia, Brazil   \n",
            "4              .NET / C# / VB.NET                 Latin America   \n",
            "..                            ...                           ...   \n",
            "116  Testing / Tester / Manual QA  Guarulhos, São Paulo, Brazil   \n",
            "117  Testing / Tester / Manual QA      Fortaleza, Ceará, Brazil   \n",
            "118                    TypeScript    Recife, Pernambuco, Brazil   \n",
            "119                         UX/UI                 Latin America   \n",
            "120                         UX/UI             São Paulo, Brazil   \n",
            "\n",
            "     Applications Expected  \n",
            "0                    476.0  \n",
            "1                    349.0  \n",
            "2                    177.0  \n",
            "3                     38.0  \n",
            "4                    199.0  \n",
            "..                     ...  \n",
            "116                  119.0  \n",
            "117                  101.0  \n",
            "118                   89.0  \n",
            "119                  209.0  \n",
            "120                  104.0  \n",
            "\n",
            "[121 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Definir escopos\n",
        "SCOPES = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "\n",
        "# Obter credenciais\n",
        "creds, _ = default()\n",
        "creds = creds.with_scopes(SCOPES)\n",
        "\n",
        "# Verificar o e-mail da conta de serviço\n",
        "service_account_email = creds.service_account_email if hasattr(creds, 'service_account_email') else \"default\"\n",
        "\n",
        "# Autorização do gspread\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Abrir a planilha do Google Sheets\n",
        "spreadsheet= gc.open('Backstage 2.0 - INDI')  # Substitua pelo nome da sua planilha\n",
        "\n",
        "worksheet = spreadsheet.worksheet(\"Filtered Data[Data-Base]\")  # Ou use .worksheet('nome da aba') se não for a primeira aba\n",
        "\n",
        "# Carregar os dados em um DataFrame\n",
        "data = worksheet.get_all_values()\n",
        "\n",
        "df = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "df=df.drop(columns = ['Tier','Semana publicación'])\n",
        "df.rename(columns={'JD Sheet Seniority': 'Seniority'}, inplace=True)\n",
        "df['Title from JD Sheet'] = df['Title from JD Sheet'].astype(str)\n",
        "df = df.loc[~df['Title from JD Sheet'].str.contains('TGHD', case=False)]\n",
        "df['Total Postulados por oferta'] = pd.to_numeric(df['Total Postulados por oferta'], errors='coerce')\n",
        "df['Applications Expected'] = df.groupby(['Technology', 'Seniority','Title from JD Sheet','Location'])['Total Postulados por oferta'].transform('mean')\n",
        "df= df.drop(columns=['Total Postulados por oferta'])\n",
        "df = df.dropna().copy()  # Corrigindo o aviso SettingWithCopyWarning\n",
        "\n",
        "df['Applications Expected'] = pd.to_numeric(df['Applications Expected'], errors='coerce')\n",
        "# Arredondando para cima\n",
        "df['Applications Expected'] = df['Applications Expected'].apply(math.ceil)\n",
        "\n",
        "df = df.astype({'Applications Expected': int}).copy()\n",
        "\n",
        "df = df.drop_duplicates(subset=['Technology', 'Seniority','Title from JD Sheet','Location'])\n",
        "\n",
        "df_sorted = df.sort_values(by=['Seniority', 'Technology', 'Applications Expected'], ascending=[True, True, False])\n",
        "df_sorted['80% of Total Expected Applications'] = df_sorted.groupby(['Technology', 'Seniority'])['Applications Expected'].transform('sum') *0.8\n",
        "results = []\n",
        "for (technology, seniority), group in df_sorted.groupby(['Technology', 'Seniority']):\n",
        "    total_applicants = group['80% of Total Expected Applications'].iloc[0]\n",
        "    cumulative_sum = 0\n",
        "    ads_count = 0\n",
        "\n",
        "    # Iterar sobre o grupo ordenado por Total Applicants decrescente\n",
        "    for index, row in group.sort_values(by='Applications Expected', ascending=False).iterrows():\n",
        "        cumulative_sum += row['Applications Expected']\n",
        "        ads_count += 1\n",
        "        if cumulative_sum >= total_applicants:\n",
        "            break\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    results.append({\n",
        "        'Technology': technology,\n",
        "        'Seniority': seniority,\n",
        "        '80% total applications Per Cluster': total_applicants,\n",
        "        'Ads to Reach 80% of Expected applications Per Cluster': ads_count\n",
        "    })\n",
        "\n",
        "# Criar um DataFrame com os resultados\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "def mark_top_ads(df, result_df):\n",
        "    df['Top Ads'] = 'ads_bellow'\n",
        "\n",
        "    for index, row in result_df.iterrows():\n",
        "        technology = row['Technology']\n",
        "        seniority = row['Seniority']\n",
        "        top_ads_count = row['Ads to Reach 80% of Expected applications Per Cluster']\n",
        "\n",
        "        group = df[(df['Technology'] == technology) & (df['Seniority'] == seniority)]\n",
        "        group = group.sort_values(by='Applications Expected', ascending=False)\n",
        "\n",
        "        for i in range(top_ads_count):\n",
        "            df.loc[group.index[i], 'Top Ads'] = 'top_ads'\n",
        "\n",
        "    return df\n",
        "\n",
        "# Chamar a função para marcar os top ads\n",
        "df = mark_top_ads(df_sorted, result_df)\n",
        "df= df.drop(columns=['80% of Total Expected Applications'])\n",
        "df.to_csv('Test>.csv',index=False)\n",
        "def new_combinations(df, existing_combinations):\n",
        "    # Crie um conjunto de combinações existentes para verificação rápida\n",
        "    existing_combinations_set = set(map(tuple, existing_combinations.values))\n",
        "\n",
        "    combinations = []\n",
        "\n",
        "    # Agrupar o DataFrame por tecnologia e senioridade\n",
        "    for (technology, seniority), group_df in df.groupby(['Technology', 'Seniority']):\n",
        "        unique_locations = set(group_df['Location'].unique())\n",
        "        unique_titles = set(group_df['Title from JD Sheet'].unique())\n",
        "\n",
        "        # Adicionar localidades correspondentes à tecnologia ao conjunto de localidades únicas\n",
        "        technology_locations = set(df[df['Technology'] == technology]['Location'].unique())\n",
        "        unique_locations |= technology_locations  # União dos conjuntos\n",
        "\n",
        "        for location in unique_locations:\n",
        "            for title in unique_titles:\n",
        "                new_combination = {'Technology': technology, 'Seniority': seniority, 'Location': location, 'Title from JD Sheet': title}\n",
        "                if tuple(new_combination.values()) not in existing_combinations_set:\n",
        "                    combinations.append(new_combination)\n",
        "\n",
        "    return pd.DataFrame(combinations)\n",
        "\n",
        "# Supondo que df_sorted seja seu DataFrame com a coluna 'Top Ads' já marcada\n",
        "existing_combinations = df_sorted[['Technology', 'Seniority', 'Location', 'Title from JD Sheet']].copy()\n",
        "\n",
        "new_combinations_df = new_combinations(df_sorted, existing_combinations)\n",
        "\n",
        "# Salvar ou imprimir o DataFrame de novas combinações\n",
        "# new_combinations_df.to_csv(\"new_combinations.csv\", index=False)\n",
        "\n",
        "import math\n",
        "spreadsheet= gc.open('Backstage 2.0 - INDI')  # Substitua pelo nome da sua planilha\n",
        "\n",
        "worksheet = spreadsheet.worksheet(\"Filtered Data[Storage]\")  # Ou use .worksheet('nome da aba') se não for a primeira aba\n",
        "\n",
        "# Carregar os dados em um DataFrame\n",
        "data = worksheet.get_all_values()\n",
        "\n",
        "data_base = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "data_base = data_base.drop(columns=['Tier', 'Semana publicación'])\n",
        "data_base.rename(columns={'JD Sheet Seniority': 'Seniority'}, inplace=True)\n",
        "data_base['Title from JD Sheet'] = data_base['Title from JD Sheet'].astype(str)\n",
        "data_base = data_base.loc[~data_base['Title from JD Sheet'].str.contains('TGHD', case=False)]\n",
        "data_base['Total Postulados por oferta'] = pd.to_numeric(data_base['Total Postulados por oferta'], errors='coerce')\n",
        "data_base['Applications Expected'] = data_base.groupby(\n",
        "    ['Technology', 'Seniority', 'Title from JD Sheet', 'Location']\n",
        ")['Total Postulados por oferta'].transform('mean')\n",
        "data_base = data_base.dropna().copy()  # Corrigindo o aviso SettingWithCopyWarning\n",
        "data_base['Applications Expected'] = pd.to_numeric(data_base['Applications Expected'], errors='coerce').apply(math.ceil)\n",
        "data_base = data_base.astype({'Applications Expected': int}).copy()\n",
        "data_base = data_base.drop(columns=['Total Postulados por oferta'])\n",
        "data_base = data_base.drop_duplicates(subset=['Technology', 'Seniority', 'Title from JD Sheet', 'Location'])\n",
        "\n",
        "def good_ads_storage(data_base):\n",
        "    filtered_ads = pd.DataFrame(columns=data_base.columns)\n",
        "\n",
        "    for (technology, seniority), group_data_base in data_base.groupby(['Technology', 'Seniority']):\n",
        "        group_sorted = group_data_base.sort_values(by='Applications Expected', ascending=False)\n",
        "        total_rows = len(group_sorted)\n",
        "\n",
        "        split_index = math.ceil(total_rows * 0.8)\n",
        "        filtered_group = group_sorted.iloc[:split_index].sort_values(by='Applications Expected', ascending=False)\n",
        "        filtered_group['Type'] = 'good_ad'\n",
        "        filtered_ads = pd.concat([filtered_ads, filtered_group])\n",
        "\n",
        "    return filtered_ads\n",
        "\n",
        "good_ads_per_cluster = good_ads_storage(data_base)\n",
        "\n",
        "spreadsheet= gc.open('Backstage 2.0 - INDI')  # Substitua pelo nome da sua planilha\n",
        "\n",
        "worksheet = spreadsheet.worksheet(\"Database Combinations\")  # Ou use .worksheet('nome da aba') se não for a primeira aba\n",
        "\n",
        "# Carregar os dados em um DataFrame\n",
        "data = worksheet.get_all_values()\n",
        "\n",
        "df3 = pd.DataFrame(data[1:], columns=data[0])\n",
        "#columns_to_remove = ['Locations', 'Concat']\n",
        "#df3 = df3.drop(columns=columns_to_remove)\n",
        "df3.rename(columns={'Tech': 'Technology', 'Job Title': 'Title from JD Sheet'}, inplace=True)\n",
        "\n",
        "def combinations_to_use(df3, new_combinations_df, df, good_ads_per_cluster):\n",
        "    # Criar um conjunto de combinações existentes para evitar duplicatas\n",
        "    existing_combinations_set = set(map(tuple, new_combinations_df[['Technology', 'Seniority', 'Location', 'Title from JD Sheet']].values))\n",
        "    existing_combinations_set |= set(map(tuple, df[['Technology', 'Seniority', 'Location', 'Title from JD Sheet']].values))\n",
        "    existing_combinations_set |= set(map(tuple, good_ads_per_cluster[['Technology', 'Seniority', 'Location', 'Title from JD Sheet']].values))\n",
        "\n",
        "    # Lista para armazenar novas combinações\n",
        "    combinations = []\n",
        "\n",
        "    # Obter localizações únicas presentes em df e good_ads_per_cluster\n",
        "    unique_locations_df = df['Location'].unique()\n",
        "    unique_locations_good_ads = good_ads_per_cluster['Location'].unique()\n",
        "    unique_locations = set(unique_locations_df).union(set(unique_locations_good_ads))\n",
        "\n",
        "    # Iterar sobre cada linha do DataFrame df3\n",
        "    for index, row in df3.iterrows():\n",
        "        technology = row['Technology']\n",
        "        seniority = row['Seniority']\n",
        "        title = row['Title from JD Sheet']\n",
        "\n",
        "        # Gerar todas as combinações possíveis de localização e título\n",
        "        for location in unique_locations:\n",
        "            new_combination = {\n",
        "                'Technology': technology,\n",
        "                'Seniority': seniority,\n",
        "                'Location': location,\n",
        "                'Title from JD Sheet': title\n",
        "            }\n",
        "            # Verificar se a nova combinação já existe no conjunto existente\n",
        "            if tuple(new_combination.values()) not in existing_combinations_set:\n",
        "                combinations.append(new_combination)\n",
        "\n",
        "    # Retornar as novas combinações como um DataFrame\n",
        "    return pd.DataFrame(combinations)\n",
        "\n",
        "# Exemplo de uso\n",
        "existing_combinations = new_combinations_df[['Technology', 'Seniority', 'Location', 'Title from JD Sheet']].copy()\n",
        "combinations_to_use_df = combinations_to_use(df3, new_combinations_df, df, good_ads_per_cluster)\n",
        "\n",
        "spreadsheet= gc.open('Backstage 2.0 - INDI')  # Substitua pelo nome da sua planilha\n",
        "\n",
        "worksheet = spreadsheet.worksheet(\"Input Allocation\")  # Ou use .worksheet('nome da aba') se não for a primeira aba\n",
        "\n",
        "# Carregar os dados em um DataFrame\n",
        "data = worksheet.get_all_values()\n",
        "\n",
        "total_ads_per_cluster_df= pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "def combine_ads(total_ads_per_cluster_df, df, new_combinations_df, combinations_to_use_df, good_ads_per_cluster):\n",
        "    combined_ads_dict = {}\n",
        "\n",
        "    # Garantir que a coluna 'Ads' seja do tipo inteiro\n",
        "    total_ads_per_cluster_df['Ads'] = total_ads_per_cluster_df['Ads'].astype(int)\n",
        "\n",
        "    for index, row in total_ads_per_cluster_df.iterrows():\n",
        "        technology = row['Technology']\n",
        "        seniority = row['Seniority']\n",
        "        total_ads = row['Ads']\n",
        "\n",
        "        ads_list = []\n",
        "\n",
        "        if total_ads > 1:\n",
        "            # Adicionar um anúncio do combinations_to_use_df com localidade presente em good_ads ou top_ads\n",
        "            localities_from_ads = df[(df['Technology'] == technology) &\n",
        "                                     (df['Seniority'] == seniority) &\n",
        "                                     (df['Top Ads'] == 'top_ads')]['Location'].unique()\n",
        "            localities_from_good_ads = good_ads_per_cluster[(good_ads_per_cluster['Technology'] == technology) &\n",
        "                                                             (good_ads_per_cluster['Seniority'] == seniority)]['Location'].unique()\n",
        "            all_localities = set(localities_from_ads) | set(localities_from_good_ads)\n",
        "            additional_ad = combinations_to_use_df[(combinations_to_use_df['Technology'] == technology) &\n",
        "                                                    (combinations_to_use_df['Seniority'] == seniority) &\n",
        "                                                    (combinations_to_use_df['Location'].isin(all_localities)) &\n",
        "                                                    (~combinations_to_use_df['Title from JD Sheet'].isin(df['Title from JD Sheet']))].head(1)\n",
        "            if not additional_ad.empty:\n",
        "                ads_list.append(additional_ad)\n",
        "                total_ads -= 1  # Ajustar total_ads para refletir o número restante de anúncios necessários\n",
        "\n",
        "        elif total_ads == 1:\n",
        "            # Adicionar um anúncio do top_ads\n",
        "            top_ads = df[(df['Technology'] == technology) & (df['Seniority'] == seniority) & (df['Top Ads'] == 'top_ads')]\n",
        "            if not top_ads.empty:\n",
        "                ads_list.append(top_ads.head(1))\n",
        "                total_ads -= 1  # Ajustar total_ads para refletir o número restante de anúncios necessários\n",
        "\n",
        "        # Filtrar os anúncios marcados como \"top_ads\" caso total_ads > 1\n",
        "        top_ads = df[(df['Technology'] == technology) & (df['Seniority'] == seniority) & (df['Top Ads'] == 'top_ads')]\n",
        "\n",
        "        # Calcular o número de anúncios restantes após os \"top_ads\"\n",
        "        if len(top_ads) > total_ads:\n",
        "            top_ads = top_ads.head(total_ads)\n",
        "\n",
        "        remaining_ads_count = total_ads - len(ads_list) - len(top_ads)\n",
        "\n",
        "        if remaining_ads_count > 0:\n",
        "            # Calcular a quantidade de anúncios de good_ads_per_cluster\n",
        "            good_ads = math.floor(remaining_ads_count * 0.3)\n",
        "            remaining_good_ads = good_ads_per_cluster[(good_ads_per_cluster['Technology'] == technology) &\n",
        "                                                      (good_ads_per_cluster['Seniority'] == seniority) &\n",
        "                                                      (~good_ads_per_cluster.index.isin(top_ads.index))].head(good_ads)\n",
        "\n",
        "            # Calcular a quantidade de anúncios de new_combinations\n",
        "            new_combinations_ads = remaining_ads_count - len(remaining_good_ads)\n",
        "            remaining_new_combinations = new_combinations_df[(new_combinations_df['Technology'] == technology) &\n",
        "                                                             (new_combinations_df['Seniority'] == seniority) &\n",
        "                                                             (~new_combinations_df.index.isin(top_ads.index))].head(new_combinations_ads)\n",
        "\n",
        "            # Adicionar remaining_good_ads e remaining_new_combinations à lista de anúncios\n",
        "            if not remaining_good_ads.empty:\n",
        "                ads_list.append(remaining_good_ads)\n",
        "            if not remaining_new_combinations.empty:\n",
        "                ads_list.append(remaining_new_combinations)\n",
        "\n",
        "        # Combinar os anúncios selecionados\n",
        "        if ads_list:\n",
        "            combined_ads = pd.concat([top_ads] + ads_list, ignore_index=True)\n",
        "            # Garantir que o número total de anúncios não exceda total_ads\n",
        "            combined_ads = combined_ads.head(row['Ads'])\n",
        "        else:\n",
        "            combined_ads = top_ads\n",
        "\n",
        "        combined_ads_dict[(technology, seniority)] = combined_ads\n",
        "\n",
        "    combined_ads = pd.concat(combined_ads_dict.values(), ignore_index=True)\n",
        "    combined_ads = combined_ads.drop_duplicates(subset=['Title from JD Sheet', 'Seniority', 'Technology', 'Location'])\n",
        "\n",
        "    ad_counts_per_cluster = combined_ads.groupby(['Technology', 'Seniority']).size().reset_index(name='Count')\n",
        "\n",
        "    # Adicionar anúncios do combinations_to_use_df para atingir o total desejado por cluster\n",
        "    for index, row in total_ads_per_cluster_df.iterrows():\n",
        "        technology = row['Technology']\n",
        "        seniority = row['Seniority']\n",
        "        total_ads = row['Ads']\n",
        "\n",
        "        # Verificar quantos anúncios já existem\n",
        "        current_count = ad_counts_per_cluster[(ad_counts_per_cluster['Technology'] == technology) &\n",
        "                                               (ad_counts_per_cluster['Seniority'] == seniority)]['Count']\n",
        "        current_count = current_count.iloc[0] if not current_count.empty else 0\n",
        "\n",
        "        # Calcular a quantidade de anúncios faltantes\n",
        "        missing_ads_count = total_ads - current_count\n",
        "\n",
        "        if missing_ads_count > 0:\n",
        "            # Selecionar anúncios adicionais do combinations_to_use_df\n",
        "            additional_ads = combinations_to_use_df[(combinations_to_use_df['Technology'] == technology) &\n",
        "                                                    (combinations_to_use_df['Seniority'] == seniority) &\n",
        "                                                    (~combinations_to_use_df.index.isin(combined_ads.index))].head(missing_ads_count)\n",
        "            if not additional_ads.empty:\n",
        "                combined_ads = pd.concat([combined_ads, additional_ads], ignore_index=True)\n",
        "\n",
        "    # Remover duplicatas finais\n",
        "    combined_ads = combined_ads.drop_duplicates(subset=['Title from JD Sheet', 'Seniority', 'Technology', 'Location'])\n",
        "\n",
        "    return combined_ads\n",
        "\n",
        "\n",
        "\n",
        "# Exemplo de uso\n",
        "combined_ads = combine_ads(total_ads_per_cluster_df, df, new_combinations_df, combinations_to_use_df, good_ads_per_cluster)\n",
        "combined_ads = combined_ads.drop(columns=['Year','Month','Top Ads'])\n",
        "\n",
        "combined_ads['Applications Expected'] = combined_ads['Applications Expected'].fillna(0)\n",
        "# Substituir valores infinitos por 0\n",
        "combined_ads.replace([float('inf'), float('-inf')], 0, inplace=True)\n",
        "\n",
        "# Converter o DataFrame para uma lista de listas, incluindo o cabeçalho\n",
        "data_to_update = [combined_ads.columns.values.tolist()] + combined_ads.values.tolist()\n",
        "\n",
        "# Abrir a planilha e a worksheet\n",
        "spreadsheet = gc.open('Backstage 2.0 - INDI')\n",
        "worksheet2 = spreadsheet.worksheet(\"Output Generation Code\")\n",
        "\n",
        "# Atualizar a planilha com os dados combinados\n",
        "worksheet2.update(data_to_update)\n",
        "\n",
        "print(combined_ads)"
      ]
    }
  ]
}